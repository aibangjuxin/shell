cat idc-servers-conn|awk '{print"\""$1"\"","->","\""$3"\""";"}'

cat idc-servers-conn|awk '{print"\""$1"\"","->","\""$3"\"""[label="$5"];"}'

cat M15|grep R420|awk -F"|" '{print$1,$3}'|awk '$2!=null {print$0}' 取主机及其序列号

awk 'BEGIN{while (a++<50) s=s "-"; print s,"分割线",s}'
-------------------------------------------------- 分割线 --------------------------------------------------

查看本地监听端口排除常用的几个
netstat -nltp|awk 'NR!=1{print$4}'|awk -F":" 'NR!=1{print$NF}'|egrep -v '(5666|22|4949|199)'
netstat -nltp|sed -n '3,$p'|awk '{print$4}'|awk -F":" 'NR!=1{print$NF}'|egrep -v '(5666|22|4949|199)'

for name in 200 206 302 400 401 403 404 416 500 501 502;do awk -v status=$name '$9 ~ /'$name'/' 35049_20150823_w3c > $name;done


::ffff:192.168.1.212:2354 ::ffff:192.168.1.111:8081
::ffff:192.168.1.212:4036 ::ffff:192.168.1.111:8081
::ffff:192.168.1.212:7844 ::ffff:192.168.1.111:8081
如果直接4和5部分的话上面 可以直接加个冒号下面的
netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g' 匹配ffff的行
结果如下
192.168.1.212:62845:192.168.2.22:6383
192.168.1.212:62844:192.168.2.22:6383
192.168.1.212:51519:192.168.1.111:8081
192.168.1.212:49841:192.168.1.111:8081
192.168.1.212:41820:192.168.1.115:6381
192.168.1.212:49397:192.168.1.111:8081
192.168.1.212:50593:192.168.1.111:8081
192.168.1.212:38610:192.168.2.62:2181

以:为分隔符 一字段不等于3字段 打印 排除自己连接自己的链接
awk -F":" '$1!~ $3'


netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -F":" '$1!~ $3'
192.168.1.212:42302:192.168.1.115:6381
192.168.1.212:42301:192.168.1.115:6381
192.168.1.212:54902:192.168.2.22:6383
192.168.1.212:54903:192.168.2.22:6383
192.168.1.212:54904:192.168.2.22:6383
192.168.1.212:54905:192.168.2.22:6383
192.168.1.212:54906:192.168.2.22:6383
192.168.1.212:38610:192.168.2.62:2181

再可以取2次 一次单独取目的主机和端口 取3和4段 去重打印


netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -F":" '$1!~ $3'|awk -F":" '{print$3" | "$4}'|sort|uniq -c
netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -F":" '$1!~ $3'|awk -F":" '{print$3" | "$4}'|sort|uniq
192.168.1.111 | 8081
192.168.1.111 | 8085
192.168.1.115 | 6381
192.168.2.22 | 6382
192.168.2.22 | 6383
192.168.2.51 | 42932
192.168.2.62 | 2181
192.168.2.62 | 60020
192.168.2.63 | 60020
192.168.2.64 | 60020
192.168.2.77 | 6380
vianet::A49 root@app-portal1:~# netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -F":" '$1!~ $3'|awk -F":" '{print "192.168.1.212 | "$3" | "$4}'|sort|uniq
192.168.1.212 | 192.168.1.111 | 8081
192.168.1.212 | 192.168.1.111 | 8085
192.168.1.212 | 192.168.1.115 | 6381
192.168.1.212 | 192.168.2.22 | 6382
192.168.1.212 | 192.168.2.22 | 6383
192.168.1.212 | 192.168.2.51 | 42932
192.168.1.212 | 192.168.2.62 | 2181
192.168.1.212 | 192.168.2.62 | 60020
192.168.1.212 | 192.168.2.63 | 60020
192.168.1.212 | 192.168.2.64 | 60020
192.168.1.212 | 192.168.2.77 | 6380
192.168.1.212 | 192.168.2.51 | 14911
# netstat -nutap|grep 14911
tcp        0      0 ::ffff:192.168.1.212:22     ::ffff:192.168.2.51:14911   ESTABLISHED 8566/1
这个22端口不是我想要的 需要排除掉
vianet::A49 root@app-portal1:~# netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -F":" '$1!~ $3 && $2!=22 && $2!=80'|awk -F":" '{print "192.168.1.212 | "$3"  | "$4}'|sort|uniq


端口
netstat -nltp|sed -n '3,$p'|awk '{print$4}'|awk -F":" '{print$NF}'



netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -v p="80|22" -F":" '$1!~ $3 && $2!~p'
变量
 lxu@lxu-laptop:~$ echo 'a b c'|awk -v v="'" '{$2=v$2""v}1'
  a 'b' c
   lxu@lxu-laptop:/home/date$ echo a b c|awk -v v="'" '{$2=v$2v}{print}'
    a 'b' c
     lxu@lxu-laptop:/home/date$ echo a b c|awk -v v="'" '{$2=v$2v}1'
      a 'b' c
netstat -nutap|grep ffff|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -v p="80|22" -F":" '$1!~ $3 && $2!~p'

vianet::A21 root@cnm:~# netstat -nutap|awk '{print$4":"$5}'|sed 's/::ffff://g'|awk -v p="80|22|6398|6387|6389|6388" -F":" '$1!~ $3 && $2!~p'
127.0.0.1:199:0.0.0.0:*
127.0.0.1:9000:0.0.0.0:*
192.168.1.20:30873:0.0.0.0:*
192.168.1.20:5666:192.168.1.248:31300
59.151.111.68:111:111.20.188.104:13395
192.168.1.20:1002:192.168.1.217:2049
192.168.1.20:123:0.0.0.0:*
59.151.111.68:123:0.0.0.0:*
127.0.0.1:123:0.0.0.0:*

将打印除第一列以外的所有列：
awk '{$1=$2=""; print $0}'  这个貌似真相等会有bug
awk '{for(i=2;i<=NF;i++){printf "%s ", $i}; printf "\n"}' 这个可以

-d指定分隔符（空格），-f指定列的列表（全部以第2列开头）
cut -d\  -f2-
符从文件 /etc/passwd 中包含字符串 /bin/bash 的行提取第一和第六个字段。
$ grep "/bin/bash" /etc/passwd | cut -d':' -f1,6

在下面这个例子中输出 /etc/passwd 文件中包含 /bin/bash 的行中除了第二个字段以外的所有字段：
要补全选择输出的字段（即反选），使用
$ grep "/bin/bash" /etc/passwd | cut -d':' --complement -f2

将打印所有但非常第一列：
awk '{$1=""; print $0}' somefile


ps aux|grep Notes|grep -v "grep"|awk '($3>60){system(/usr/bin/pkill Notes)}'

ll|grep -v mount|awk 'NR!=1 {print$NF}'

vianet::prod-bbs01 root@a28-v01:/# for in in `ll|grep -v mount|awk 'NR!=1 {print$NF}'|grep -v mnt`;do du -sh $in ;done


vianet::mail root@a57:~# netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
ESTABLISHED 283
FIN_WAIT1 1
TIME_WAIT 12
vianet::mail root@a57:~# ss -ant | awk 'NR>1 {++s[$1]} END {for(k in s) print k,s[k]}'
LISTEN 18
ESTAB 277
FIN-WAIT-1 1
TIME-WAIT 12

用了三个的
awk -F"\\\] \\\[" '{print $3}' a.sh

awk -F"\\\] \\\[" '$3 ~ /200/ && $4 >=$(NF-2)' 2014-04-01-0000-2330_dl.op.com.cn.log > 0401OK


日志中访问量最大的前十个IP及其访问次数。

最常见的shell命令：cat access.log | cut -d ‘ ‘ -f 4 |sort|uniq -c|sort -nr|head

我最常用的awk命令：awk ‘{a[$4]++}END{for(i in a){print a[i],i}}’ access.log | sort -nr | head


➜  Downloads  cat a.sh
[2014-03-25T14:49:40+08:00] [218.92.221.151] [200] [14275] [-] [opdl_uid=D671973B042731535D21F66902CD0A03] [220.181.157.196] [dl-src.op.com] [GET /lite/w/oplite.jar HTTP/1.1] [http://dl.op.com/lite/w/oplite.jar] [Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/532.0 (KHTML, like Gecko) Chrome/3.0.195.32 Safari/532.0] [-] [14275] [-] [-]

awk -F"\\\] \\\[" '$5!="-" && $6!="-"' 2014-04-11-0000-2330_dl.op.com.cn.log

➜  Downloads  awk '$3 ~ /200/ && $4==$(NF-2)' a.sh
[2014-03-25T14:49:40+08:00] [218.92.221.151] [200] [14275] [-] [opdl_uid=D671973B042731535D21F66902CD0A03] [220.181.157.196] [dl-src.op.com] [GET /lite/w/oplite.jar HTTP/1.1] [http://dl.op.com/lite/w/oplite.jar] [Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/532.0 (KHTML, like Gecko) Chrome/3.0.195.32 Safari/532.0] [-] [14275] [-] [-]


在awk编程中,
BEGIN模式后面跟一个操作模块,如:BEGIN{...},在awk处理输入文件里的任意行之前执行该模块,其实不用任何输入文件就能测试一个BEGIN操作模块,因为直到BEGIN操作模块完成之后,awk才开始读取输入.BEGIN操作通常用来改变OFS,FS,RS等awk内制变量的值.
如:
awk 'BEGIN{FS=":";OFS="\t";ORS="\n"}{print $0}' filename
在处理输入文件之前,把域分隔符FS设定成冒号,输出域分隔符OFS设定成TAB键,并把输出记录分隔符ORS设定成一个换行符.
awk 'BEGIN{OFS="\t"} {print $1,$2,$3}'

awk 'BEGIN{FS=":"} {print$1}' /etc/passwd
awk -F":" '{print$1}' /etc/passwd

END模式不于任何输入行匹配,但是执行任何与END模式相关的操作.在所有输入行处理完成之后在处理END模式.
如:
awk 'END{print "some strings" NR }' filename
在awk处理完成文件后再执行END模块,NR的值是度入的最后一条记录号.

BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。

END：让用户在最后一条输入记录被读取之后发生的动作。


14.2. BEGIN模块

BEGIN 模块后紧跟着动作块，这个动作块在awk处理任何输入文件之前执行。所以它可以在没有任何输入的情况下进行测试。它通常用来改变内建变量的值，如OFS, RS和FS等，以及打印标题。如：$ awk 'BEGIN{FS=":"; OFS="\t"; ORS="\n\n"}{print $1,$2,$3} test。上式表示，在处理输入文件以前，域分隔符(FS)被设为冒号，输出文件分隔符(OFS)被设置为制表符，输出记录分隔符(ORS)被设置为两个 换行符。$ awk 'BEGIN{print "TITLE TEST"}只打印标题。

14.3. END模块

END不匹配任何的输入文件，但是执行动作块中的所有动作，它在整个输入文件处理完成后被执行。如$ awk 'END{print "The number of records is" NR}' test，上式将打印所有被处理的记录数。



awk 用法：awk ' pattern {action} '

变量名 含义
ARGC 命令行变元个数
ARGV 命令行变元数组
FILENAME 当前输入文件名
FNR 当前文件中的记录号
FS 输入域分隔符，默认为一个空格
RS 输入记录分隔符
NF 当前记录里域[字段]个数
NR 到目前为止记录数 如$ awk '{print NR,$0}' test将输出test文件中所有记录，并在记录前显示记录号。
OFS 输出域分隔符
ORS 输出记录分隔符

awk '/\postfix\/smtpd/ && $11 ~"450" {print$0}' maillog


awk '$8 ~/"404"/ && $10 ~/op.com/ {print "http://r.op.com"$6$10}' /usr/local/nginx/logs/r2.access.log${DATE}.log|grep -v '"-"$'


$0变量：它指的是整条记录。如$ awk '{print $0}' test将输出test文件中的所有记录。

# cat a.sh
1.1.1.1  a
2.2.2.2  b
8.8.8.8 c
3.3.3.3 d
5.5.5.5 3
2.2.2.2 f
# awk '$1 ~/1.1.1.1|2.2.2.2/ {print}' a.sh
1.1.1.1  a
2.2.2.2  b
2.2.2.2 f
awk '$1 ~/1.1.1.1|2.2.2.2/' a.sh

1、awk '/101/'               file 显示文件file中包含101的匹配行。
awk '/No such file or directory/{print$7}' /download/logs/error.log
   awk '/101/,/105/'         file
   awk '$1 == 5'             file 等价于awk '{if($1==5)print$0}'
   awk '$1 == "CT"'          file 注意必须带双引号
   awk '$1 * $2 >100 '       file
   awk '$2 >5 && $2<=15'     file
awk '$NF=="ms"' a.sh

awk '{if($(NF-1)==500) print $0}'
NF-1那个字段
awk '$(NF-1)==500'


lxu@lxu-laptop:~$ cat mum
4 5
3 4
2 3
7 8
lxu@lxu-laptop:~$ awk '$1 * $2 > 12' mum
4 5
7 8
lxu@lxu-laptop:~$ awk '{if($1 * $2 > 12) print $0} ' mum
4 5
7 8

$ awk '{if($2 > 5) print $0} ' mum
7 8

awk '{if($5==12)print$0;else print$1,$2,$3,$4,"ABC",$6}'
假如$5=12那么打印整个域，否则用ABC替换第五个域

2、awk '{print NR,NF,$1,$NF,}' file 显示文件file的当前记录号、域数和每一行的第一个和最后一个域。
   awk '/101/ {print $1,$2 + 10}' file 显示文件file的匹配行的第一、二个域加10。
   awk '/101/ {print $1$2}'  file
   awk '/101/ {print $1 $2}' file 显示文件file的匹配行的第一、二个域，但显示时域中间没有分隔符。
3、df | awk '$4>1000000 '         通过管道符获得输入，如：显示第4个域满足条件的行。
   df|awk '{if($4>1000000);print$4}'

4、awk -F "|" '{print $1}'   file 按照新的分隔符“|”进行操作。
   awk  'BEGIN { FS="[: \t|]" }
   {print $1,$2,$3}'       file 通过设置输入分隔符（FS="[: \t|]"）修改输入分隔符。

   Sep="|"
   awk -F $Sep '{print $1}'  file 按照环境变量Sep的值做为分隔符。
   awk -F '[ :\t|]' '{print $1}' file 按照正则表达式的值做为分隔符，这里代表空格、:、TAB、|同时做为分隔符。
   awk -F '[][]'    '{print $1}' file 按照正则表达式的值做为分隔符，这里代表[、]
5、awk -f awkfile       file 通过文件awkfile的内容依次进行控制。
   cat awkfile
/101/{print "\047 Hello! \047"} --遇到匹配行以后打印 ' Hello! '.\047代表单引号。
{print $1,$2}                   --因为没有模式控制，打印每一行的前两个域。
6、awk '$1 ~ /101/ {print $1}' file 显示文件中第一个域匹配101的行（记录）
awk '$8 ~/"404"/ && $10 ~/op.com/ {print "http://r.op.com"$6$10}' /usr/local/nginx/logs/r2.access.log${DATE}.log|grep -v '"-"$'
第八个域 匹配404的行

 用来在记录或者域内匹配正则表达式。
 如$ awk '$1 ~/^root/' test将显示test文件第一列中以root开头的行。。
7、awk   'BEGIN { OFS="%"}
   {print $1,$2}'           file 通过设置输出分隔符（OFS="%"）修改输出格式。
8、awk   'BEGIN { max=100 ;print "max=" max}             BEGIN 表示在处理任意行之前进行的操作。
   {max=($1 >max ?$1:max); print $1,"Now max is "max}' file 取得文件第一个域的最大值。
   （表达式1?表达式2:表达式3 相当于：
   if (表达式1)
       表达式2
   else
       表达式3
   awk '{print ($1>4 ? "high "$1: "low "$1)}' file
9、awk '$1 * $2 >100 {print $1}' file 显示文件中第一个域匹配101的行（记录）。
比较表达式

10、awk '{$1 == 'Chi' {$3 = 'China'; print}' file 找到匹配行后先将第3个域替换后再显示该行（记录）。
    awk '{$7 %= 3; print $7}'  file 将第7域被3除，并将余数赋给第7域再打印。
for example:
每60行数据插入“日期         姓名      金额         交易号 ”
awk 'NR%60==1{print "日期         姓名      金额         交易号"}1' urfile
sed '1~59i\name date money number' urfile

11、awk '/tom/ {wage=$2+$3; printf wage}' file 找到匹配行后为变量wage赋值并打印该变量。
12、awk '/tom/ {count++;}
         END {print "tom was found "count" times"}' file END表示在所有输入行处理完后进行处理。
13、awk 'gsub(/\$/,"");gsub(/,/,""); cost+=$4;
         END {print "The total is $" cost>"filename"}'    file gsub函数用空串替换$和,再将结果输出到filename中。
    1 2 3 $1,200.00
    1 2 3 $2,300.00
    1 2 3 $4,000.00

    awk '{gsub(/\$/,"");gsub(/,/,"");
    if ($4>1000&&$4<2000) c1+=$4;
    else if ($4>2000&&$4<3000) c2+=$4;
    else if ($4>3000&&$4<4000) c3+=$4;
    else c4+=$4; }
    END {printf  "c1=[%d];c2=[%d];c3=[%d];c4=[%d]\n",c1,c2,c3,c4}"' file
    通过if和else if完成条件语句

    awk '{gsub(/\$/,"");gsub(/,/,"");
    if ($4>3000&&$4<4000) exit;
    else c4+=$4; }
    END {printf  "c1=[%d];c2=[%d];c3=[%d];c4=[%d]\n",c1,c2,c3,c4}"' file
    通过exit在某条件时退出，但是仍执行END操作。
    awk '{gsub(/\$/,"");gsub(/,/,"");
    if ($4>3000) next;
    else c4+=$4; }
    END {printf  "c4=[%d]\n",c4}"' file
    通过next在某条件时跳过该行，对下一行执行操作。


14、awk '{ print FILENAME,$0 }' file1 file2 file3>fileall 把file1、file2、file3的文件内容全部写到fileall中，格式为
    打印文件并前置文件名。
15、awk ' $1!=previous { close(previous); previous=$1 }
    {print substr($0,index($0," ") +1)>$1}' fileall 把合并后的文件重新分拆为3个文件。并与原文件一致。
16、awk 'BEGIN {"date"|getline d; print d}'         通过管道把date的执行结果送给getline，并赋给变量d，然后打印。
17、awk 'BEGIN {system("echo \"Input your name:\\c\""); getline d;print "\nYour name is",d,"\b!\n"}'
    通过getline命令交互输入name，并显示出来。
    awk 'BEGIN {FS=":"; while(getline< "/etc/passwd" >0) { if($1~"050[0-9]_") print $1}}'
    打印/etc/passwd文件中用户名包含050x_的用户名。

18、awk '{ i=1;while(i<NF) {print NF,$i;i++}}' file 通过while语句实现循环。
    awk '{ for(i=1;i<NF;i++) {print NF,$i}}'   file 通过for语句实现循环。
变量的初始值为1 若i小于可等于NF(记录中域的个数),则执行打印语句，且i增加1。直到i的值大于NF.
    type file|awk -F "/" '
    { for(i=1;i<NF;i++)
    { if(i==NF-1) { printf "%s",$i }
    else { printf "%s/",$i } }}'               显示一个文件的全路径。
    用for和if显示日期
    awk  'BEGIN {
for(j=1;j<=12;j++)
{ flag=0;
  printf "\n%d月份\n",j;
        for(i=1;i<=31;i++)
        {
        if (j==2&&i>28) flag=1;
        if ((j==4||j==6||j==9||j==11)&&i>30) flag=1;
        if (flag==0) {printf "%02d%02d ",j,i}
        }
}
}'
19、在awk中调用系统变量必须用单引号，如果是双引号，则表示字符串
Flag=abcd
awk '{print '$Flag'}'   结果为abcd
awk '{print  "$Flag"}'   结果为$Flag

$ awk '/^(no|so)/' test-----打印所有以模式no或so开头的行
$ awk '/^[ns]/{print $1}' test-----如果记录以n或s开头，就打印这个记录。
$ awk '$1 == 100 || $2 < 50' test-----如果第一个或等于100或者第二个域小于50，则打印该行。


1. awk简介

awk 是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入、一个或多个文件，或其它命令的输出。它支持用户自定义函数和 动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk的处理文本和数据的方式是这 样的，它逐行扫描文件，从第一行到最后一行，寻找匹配的特定模式的行，并在这些行上进行你想要的操作。如果没有指定处理动作，则把匹配的行显示到标准输出 (屏幕)，如果没有指定模式，则所有被操作所指定的行都被处理。awk分别代表其作者姓氏的第一个字母。因为它的作者是三个人，分别是Alfred Aho、Brian Kernighan、Peter Weinberger。gawk是awk的GNU版本，它提供了Bell实验室和GNU的一些扩展。下面介绍的awk是以GUN的gawk为例的，在 linux系统中已把awk链接到gawk，所以下面全部以awk进行介绍。

2. awk命令格式和选项

2.1. awk的语法有两种形式

awk [options] 'script' var=value file(s)

awk [options] -f scriptfile var=value file(s)

2.2. 命令选项

-F fs or --field-separator fs
指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。

-v var=value or --asign var=value
赋值一个用户定义变量。

-f scripfile or --file scriptfile
从脚本文件中读取awk命令。

-mf nnn and -mr nnn
对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。

-W compact or --compat, -W traditional or --traditional
在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。

-W copyleft or --copyleft, -W copyright or --copyright
打印简短的版权信息。

-W help or --help, -W usage or --usage
打印全部awk选项和每个选项的简短说明。

-W lint or --lint
打印不能向传统unix平台移植的结构的警告。

-W lint-old or --lint-old
打印关于不能向传统unix平台移植的结构的警告。

-W posix
打开兼容模式。但有以下限制，不识别：\x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符**和**=不能代替^和^=；fflush无效。

-W re-interval or --re-inerval
允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。

-W source program-text or --source program-text
使用program-text作为源代码，可与-f命令混用。

-W version or --version
打印bug报告信息的版本。

3. 模式和操作

awk脚本是由模式和操作组成的：
pattern {action} 如$ awk '/root/' test，或$ awk '$3 < 100' test。

两者是可选的，如果没有模式，则action应用到全部记录，如果没有action，则输出匹配全部记录。默认情况下，每一个输入行都是一条记录，但用户可通过RS变量指定不同的分隔符进行分隔。

3.1. 模式

模式可以是以下任意一个：

/正则表达式/：使用通配符的扩展集。

关系表达式：可以用下面运算符表中的关系运算符进行操作，可以是字符串或数字的比较，如$2>%1选择第二个字段比第一个字段长的行。

模式匹配表达式：用运算符~(匹配)和~!(不匹配)。

模式，模式：指定一个行的范围。该语法不能包括BEGIN和END模式。

BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。

END：让用户在最后一条输入记录被读取之后发生的动作。

3.2. 操作

操作由一人或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内。主要有四部份：

变量或数组赋值

输出命令

内置函数

控制流命令

4. awk的环境变量

Table 1. awk的环境变量

变量     描述
$n     当前记录的第n个字段，字段间由FS分隔。
$0     完整的输入记录。
ARGC     命令行参数的数目。
ARGIND     命令行中当前文件的位置(从0开始算)。
ARGV     包含命令行参数的数组。
CONVFMT     数字转换格式(默认值为%.6g)
ENVIRON     环境变量关联数组。
ERRNO     最后一个系统错误的描述。
FIELDWIDTHS     字段宽度列表(用空格键分隔)。
FILENAME     当前文件名。
FNR     同NR，但相对于当前文件。
FS     字段分隔符(默认是任何空格)。
IGNORECASE     如果为真，则进行忽略大小写的匹配。
NF     当前记录中的字段数。当前行拥有的列数
lxu@lxu-laptop:~$ cat def|awk -F"," '{print NF}'
6
lxu@lxu-laptop:~$ cat def
jerry,lzhou,xfcao,jduan,fzhou,
lxu@lxu-laptop:~$ cat def|awk -F"," '{print $5}'
fzhou
lxu@lxu-laptop:~$ awk -F, '{for(i=1;i<NF;i++){print $i","}}'

NR     当前记录数。
OFMT     数字的输出格式(默认值是%.6g)。
OFS     输出字段分隔符(默认值是一个空格)。
ORS     输出记录分隔符(默认值是一个换行符)。
RLENGTH     由match函数所匹配的字符串的长度。
RS     记录分隔符(默认是一个换行符)。
RSTART     由match函数所匹配的字符串的第一个位置。
SUBSEP     数组下标分隔符(默认值是\034)。
5. awk运算符

Table 2. 运算符
 awk 'BEGIN{a=4;b=5;print a*b}'
运算符     描述
= += -= *= /= %= ^= **=     赋值
?:     C条件表达式
||     逻辑或
&&     逻辑与
~ ~!     匹配正则表达式和不匹配正则表达式
< <= > >= != ==     关系运算符
空格     连接
+ -     加，减
* / &     乘，除与求余
+ - !     一元加，减和逻辑非
^ ***     求幂
++ --     增加或减少，作为前缀或后缀
$     字段引用
in     数组成员
6. 记录和域

6.1. 记录

awk把每一个以换行符结束的行称为一个记录。

记录分隔符：默认的输入和输出的分隔符都是回车，保存在内建变量ORS和RS中。

$0变量：它指的是整条记录。如$ awk '{print $0}' test将输出test文件中的所有记录。

变量NR：一个计数器，每处理完一条记录，NR的值就增加1。如$ awk '{print NR,$0}' test将输出test文件中所有记录，并在记录前显示记录号。

6.2. 域

记录中每个单词称做“域”，默认情况下以空格或tab分隔。awk可跟踪域的个数，并在内建变量NF中保存该值。如$ awk '{print $1,$3}' test将打印test文件中第一和第三个以空格分开的列(域)。

6.3. 域分隔符

内建变量FS保存输入域分隔符的值，默认是空格或tab。我们可以通过-F命令行选项修改FS的值。如$ awk -F: '{print $1,$5}' test将打印以冒号为分隔符的第一，第五列的内容。

可以同时使用多个域分隔符，这时应该把分隔符写成放到方括号中，如$awk -F'[:\t]' '{print $1,$3}' test，表示以空格、冒号和tab作为分隔符。

输出域的分隔符默认是一个空格，保存在OFS中。如$ awk -F: '{print $1,$5}' test，$1和$5间的逗号就是OFS的值。

7. gawk专用正则表达式元字符

一般通用的元字符集就不讲了，可参考我的Sed和Grep学习笔记。以下几个是gawk专用的，不适合unix版本的awk。

\Y
匹配一个单词开头或者末尾的空字符串。

\B
匹配单词内的空字符串。

\<
匹配一个单词的开头的空字符串，锚定开始。

\>
匹配一个单词的末尾的空字符串，锚定末尾。

\w
匹配一个字母数字组成的单词。

\W
匹配一个非字母数字组成的单词。

\‘
匹配字符串开头的一个空字符串。

\'
匹配字符串末尾的一个空字符串。

8. POSIX字符集

可参考我的Grep学习笔记

9. 匹配操作符(~)

用来在记录或者域内匹配正则表达式。如$ awk '$1 ~/^root/' test将显示test文件第一列中以root开头的行。

10. 比较表达式

conditional expression1 ? expression2: expression3，例如：$ awk '{max = {$1 > $3} ? $1: $3: print max}' test。如果第一个域大于第三个域，$1就赋值给max，否则$3就赋值给max。

$ awk '$1 + $2 < 100' test。如果第一和第二个域相加大于100，则打印这些行。

$ awk '$1 > 5 && $2 < 10' test,如果第一个域大于5，并且第二个域小于10，则打印这些行。

11. 范围模板

范围模板匹配从第一个模板的第一次出现到第二个模板的第一次出现之间所有行。如果有一个模板没出现，则匹配到开头或末尾。如$ awk '/root/,/mysql/' test将显示root第一次出现到mysql第一次出现之间的所有行。
打印XXX第一次出现的行号
awk '/XXX/{print NR;exit}' urfile

12. 一个验证passwd文件有效性的例子

$ cat /etc/passwd | awk -F: '\
NF != 7{\
printf("line %d,does not have 7 fields:%s\n",NR,$0)}\
$1 !~ /[A-Za-z0-9]/{printf("line %d,non alpha and numeric user id:%d: %s\n,NR,$0)}\
$2 == "*" {printf("line %d, no password: %s\n",NR,$0)}'

cat把结果输出给awk，awk把域之间的分隔符设为冒号。


如果域的数量(NF)不等于7，就执行下面的程序。


printf打印字符串"line ?? does not have 7 fields"，并显示该条记录。


如果第一个域没有包含任何字母和数字，printf打印“no alpha and numeric user id" ，并显示记录数和记录。


如果第二个域是一个星号，就打印字符串“no passwd”，紧跟着显示记录数和记录本身。

13. 几个实例

$ awk '/^(no|so)/' test-----打印所有以模式no或so开头的行。

$ awk '/^[ns]/{print $1}' test-----如果记录以n或s开头，就打印这个记录。

$ awk '$1 ~/[0-9][0-9]$/(print $1}' test-----如果第一个域以两个数字结束就打印这个记录。

$ awk '$1 == 100 || $2 < 50' test-----如果第一个或等于100或者第二个域小于50，则打印该行。

$ awk '$1 != 10' test-----如果第一个域不等于10就打印该行。

$ awk '/test/{print $1 + 10}' test-----如果记录包含正则表达式test，则第一个域加10并打印出来。

$ awk '{print ($1 > 5 ? "ok "$1: "error"$1)}' test-----如果第一个域大于5则打印问号后面的表达式值，否则打印冒号后面的表达式值。

$ awk '/^root/,/^mysql/' test----打印以正则表达式root开头的记录到以正则表达式mysql开头的记录范围内的所有记录。如果找到一个新的正则表达式root开头的记 录，则继续打印直到下一个以正则表达式mysql开头的记录为止，或到文件末尾。

14. awk编程

14.1. 变量

在awk中，变量不需要定义就可以直接使用，变量类型可以是数字或字符串。

赋 值格式：Variable = expression，如$ awk '$1 ~/test/{count = $2 + $3; print count}' test,上式的作用是,awk先扫描第一个域，一旦test匹配，就把第二个域的值加上第三个域的值，并把结果赋值给变量count，最后打印出来。

awk 可以在命令行中给变量赋值，然后将这个变量传输给awk脚本。如$ awk -F: -f awkscript month=4 year=2004 test，上式的month和year都是自定义变量，分别被赋值为4和2004。在awk脚本中，这些变量使用起来就象是在脚本中建立的一样。注意，如 果参数前面出现test，那么在BEGIN语句中的变量就不能被使用。

域变量也可被赋值和修改，如$ awk '{$2 = 100 + $1; print }' test,上式表示，如果第二个域不存在，awk将计算表达式100加$1的值，并将其赋值给$2，如果第二个域存在，则用表达式的值覆盖$2原来的值。 再例如：$ awk '$1 == "root"{$1 ="test";print}' test，如果第一个域的值是“root”，则把它赋值为“test”，注意，字符串一定要用双引号。

内建变量的使用。 变量列表在前面已列出，现在举个例子说明一下。$ awk -F: '{IGNORECASE=1; $1 == "MARY"{print NR,$1,$2,$NF}'test，把IGNORECASE设为1代表忽略大小写，打印第一个域是mary的记录数、第一个域、第二个域和最后一个 域。

14.2. BEGIN模块

BEGIN 模块后紧跟着动作块，这个动作块在awk处理任何输入文件之前执行。所以它可以在没有任何输入的情况下进行测试。它通常用来改变内建变量的值，如OFS, RS和FS等，以及打印标题。如：$ awk 'BEGIN{FS=":"; OFS="\t"; ORS="\n\n"}{print $1,$2,$3} test。上式表示，在处理输入文件以前，域分隔符(FS)被设为冒号，输出文件分隔符(OFS)被设置为制表符，输出记录分隔符(ORS)被设置为两个 换行符。$ awk 'BEGIN{print "TITLE TEST"}只打印标题。

14.3. END模块

END不匹配任何的输入文件，但是执行动作块中的所有动作，它在整个输入文件处理完成后被执行。如$ awk 'END{print "The number of records is" NR}' test，上式将打印所有被处理的记录数。

14.4. 重定向和管道

awk 可使用shell的重定向符进行重定向输出，如：$ awk '$1 = 100 {print $1 > "output_file" }' test。上式表示如果第一个域的值等于100，则把它输出到output_file中。也可以用>>来重定向输出，但不清空文件，只做追加 操作。

输出重定向需用到getline函数。getline从标准输入、管道或者当前正在处理的文件之外的其他输入文件 获得输入。它负责从输入获得下一行的内容，并给NF,NR和FNR等内建变量赋值。如果得到一条记录，getline函数返回1，如果到达文件的末尾就返 回0，如果出现错误，例如打开文件失败，就返回-1。如：

$ awk 'BEGIN{ "date" | getline d; print d}' test。执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量d，并打印它。

$ awk 'BEGIN{"date" | getline d; split(d,mon); print mon[2]}' test。执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给d，split函数把变量d转 化成数组mon，然后打印数组mon的第二个元素。

$ awk 'BEGIN{while( "ls" | getline) print}'，命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。这里没有输入文件，因为 BEGIN块在打开输入文件前执行，所以可以忽略输入文件。

$ awk 'BEGIN{printf "What is your name?"; getline name < "/dev/tty" } $1 ~name {print "Found" name on line ", NR "."} END{print "See you," name "."} test。在屏幕上打印”What is your name?",并等待用户应答。当一行输入完毕后，getline函数从终端接收该行输入，并把它储存在自定义变量name中。如果第一个域匹配变量 name的值，print函数就被执行，END块打印See you和name的值。

$ awk 'BEGIN{while (getline < "/etc/passwd" > 0) lc++; print lc}'。awk将逐行读取文件/etc/passwd的内容，在到达文件末尾前，计数器lc一直增加，当到末尾时，打印lc的值。注意，如果文件不存 在，getline返回-1，如果到达文件的末尾就返回0，如果读到一行，就返回1，所以命令 while (getline < "/etc/passwd")在文件不存在的情况下将陷入无限循环，因为返回-1表示逻辑真。

可以在awk中打开一个管 道，且同一时刻只能有一个管道存在。通过close()可关闭管道。如：$ awk '{print $1, $2 | "sort" }' test END {close("sort")}。awd把print语句的输出通过管道作为linux命令sort的输入,END块执行关闭管道操作。

system函数可以在awk中执行linux的命令。如：$ awk 'BEGIN{system("clear")'。



fflush函数用以刷新输出缓冲区，如果没有参数，就刷新标准输出的缓冲区，如果以空字符串为参数，如fflush(""),则刷新所有文件和管道的输出缓冲区。

14.5. 条件语句

awk中的条件语句是从C语言中借鉴过来的，可控制程序的流程。

14.5.1. if语句

格式：
        {if (expression){
                   statement; statement; ...
                     }
        }
$ awk '{if ($1 <$2) print $2 "too high"}' test。如果第一个域小于第二个域则打印。

$ awk '{if ($1 < $2) {count++; print "ok"}}' test.如果第一个域小于第二个域，则count加一，并打印ok。

14.5.2. if/else语句，用于双重判断。

格式：
        {if (expression){
                   statement; statement; ...
                       }
        else{
                   statement; statement; ...
                       }
        }
$ awk '{if ($1 > 100) print $1 "bad" ; else print "ok"}' test。如果$1大于100则打印$1 bad,否则打印ok。

$ awk '{if ($1 > 100){ count++; print $1} else {count--; print $2}' test。如果$1大于100，则count加一，并打印$1，否则count减一，并打印$1。

14.5.3. if/else else if语句，用于多重判断。

格式：
        {if (expression){
                    statement; statement; ...
                   }
        else if (expression){
                    statement; statement; ...
                   }
        else if (expression){
                    statement; statement; ...
                   }
        else {
                   statement; statement; ...
             }
        }
14.6. 循环

awk有三种循环:while循环；for循环；special for循环。

$ awk '{ i = 1; while ( i <= NF ) { print NF,$i; i++}}' test。变量的初始值为1，若i小于可等于NF(记录中域的个数),则执行打印语句，且i增加1。直到i的值大于NF.

$ awk '{for (i = 1; i<NF; i++) print NF,$i}' test。作用同上。

breadkcontinue语句。break用于在满足条件的情况下跳出循环；continue用于在满足条件的情况下忽略后面的语句，直接返回循环的顶端。如：

{for ( x=3; x<=NF; x++)
            if ($x<0){print "Bottomed out!"; break}}
{for ( x=3; x<=NF; x++)
            if ($x==0){print "Get next item"; continue}}

next语句从输入文件中读取一行，然后从头开始执行awk脚本。如：

{if ($1 ~/test/){next}
    else {print}
}

exit语句用于结束awk程序，但不会略过END块。退出状态为0代表成功，非零值表示出错。

14.7. 数组

awk中的数组的下标可以是数字和字母，称为关联数组。

14.7.1. 下标与关联数组

用 变量作为数组下标。如：$ awk {name[x++]=$2};END{for(i=0;i<NR;i++) print i,name[i]}' test。数组name中的下标是一个自定义变量x，awk初始化x的值为0，在每次使用后增加1。第二个域的值被赋给name数组的各个元素。在END 模块中，for循环被用于循环整个数组，从下标为0的元素开始，打印那些存储在数组中的值。因为下标是关健字，所以它不一定从0开始，可以从任何值开始。

special for循环用于读取关联数组中的元素。格式如下：

{for (item in arrayname){
         print arrayname[item]
         }
}
$ awk '/^tom/{name[NR]=$1}; END{for(i in name){print name[i]}}' test。打印有值的数组元素。打印的顺序是随机的。
用字符串作为下标。如：count["test"]

用 域值作为数组的下标。一种新的for循环方式，for (index_value in array) statement。如:$ awk '{count[$1]++} END{for(name in count) print name,count[name]}' test。该语句将打印$1中字符串出现的次数。它首先以第一个域作数组count的下标，第一个域变化，索引就变化。

delete 函数用于删除数组元素。如：$ awk '{line[x++]=$1} END{for(x in line) delete(line[x])}' test。分配给数组line的是第一个域的值，所有记录处理完成后，special for循环将删除每一个元素。

14.8. awk的内建函数

14.8.1. 字符串函数

sub函数匹配记录中最大、最靠左边的子字符串的正则表达式，并用替换字符串替换这些字符串。如果没有指定目标字符串就默认使用整个记录。替换只发生在第一次匹配的时候。格式如下：

            sub (regular expression, substitution string):
            sub (regular expression, substitution string, target string)
实例：

            $ awk '{ sub(/test/, "mytest"); print }' testfile
            $ awk '{ sub(/test/, "mytest"); $1}; print }' testfile
第一个例子在整个记录中匹配，替换只发生在第一次匹配发生的时候。如要在整个文件中进行匹配需要用到gsub

第二个例子在整个记录的第一个域中进行匹配，替换只发生在第一次匹配发生的时候。

gsub函数作用如sub，但它在整个文档中进行匹配。格式如下：

            gsub (regular expression, substitution string)
            gsub (regular expression, substitution string, target string)
实例：

            $ awk '{ gsub(/test/, "mytest"); print }' testfile
            $ awk '{ gsub(/test/, "mytest"), $1 }; print }' testfile
第一个例子在整个文档中匹配test，匹配的都被替换成mytest。

第二个例子在整个文档的第一个域中匹配，所有匹配的都被替换成mytest。

index函数返回子字符串第一次被匹配的位置，偏移量从位置1开始。格式如下：

          index(string, substring)
实例：

            $ awk '{ print index("test", "mytest") }' testfile
实例返回test在mytest的位置，结果应该是3。

length函数返回记录的字符数。格式如下：

            length( string )
            length
实例：

            $ awk '{ print length( "test" ) }'
            $ awk '{ print length }' testfile
第一个实例返回test字符串的长度。

第二个实例返回testfile文件中第条记录的字符数。

substr函数返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串。格式如下：

            substr( string, starting position )
            substr( string, starting position, length of string )
实例：

            $ awk '{ print substr( "hello world", 7,11 ) }'
上例截取了world子字符串。

match函数返回在字符串中正则表达式位置的索引，如果找不到指定的正则表达式则返回0。match函数会设置内建变量RSTART为字符串中子字符串的开始位置，RLENGTH为到子字符串末尾的字符个数。substr可利于这些变量来截取字符串。函数格式如下：

            match( string, regular expression )
实例：

            $ awk '{start=match("this is a test",/[a-z]+$/); print start}'
            $ awk '{start=match("this is a test",/[a-z]+$/); print start, RSTART, RLENGTH }'
第一个实例打印以连续小写字符结尾的开始位置，这里是11。

第二个实例还打印RSTART和RLENGTH变量，这里是11(start)，11(RSTART)，4(RLENGTH)。

toupper和tolower函数可用于字符串大小间的转换，该功能只在gawk中有效。格式如下：

            toupper( string )
            tolower( string )
实例：

            $ awk '{ print toupper("test"), tolower("TEST") }'
split函数可按给定的分隔符把字符串分割为一个数组。如果分隔符没提供，则按当前FS值进行分割。格式如下：

            split( string, array, field separator )
            split( string, array )
实例：

            $ awk '{ split( "20:18:00", time, ":" ); print time[2] }'
上例把时间按冒号分割到time数组内，并显示第二个数组元素18。


lxu@lxu-laptop:~$ awk 'BEGIN{s="ABC";print tolower(s)}'
abc


14.8.2. 时间函数

systime函数返回从1970年1月1日开始到当前时间(不计闰年)的整秒数。格式如下：

            systime()
实例：

            $ awk '{ now = systime(); print now }'
strftime函数使用C库中的strftime函数格式化时间。格式如下：

            systime( [format specification][,timestamp] )
Table 3. 日期和时间格式说明符

格式     描述
%a     星期几的缩写(Sun)
%A     星期几的完整写法(Sunday)
%b     月名的缩写(Oct)
%B     月名的完整写法(October)
%c     本地日期和时间
%d     十进制日期
%D     日期 08/20/99
%e     日期，如果只有一位会补上一个空格
%H     用十进制表示24小时格式的小时
%I     用十进制表示12小时格式的小时
%j     从1月1日起一年中的第几天
%m     十进制表示的月份
%M     十进制表示的分钟
%p     12小时表示法(AM/PM)
%S     十进制表示的秒
%U     十进制表示的一年中的第几个星期(星期天作为一个星期的开始)
%w     十进制表示的星期几(星期天是0)
%W     十进制表示的一年中的第几个星期(星期一作为一个星期的开始)
%x     重新设置本地日期(08/20/99)
%X     重新设置本地时间(12：00：00)
%y     两位数字表示的年(99)
%Y     当前月份
%Z     时区(PDT)
%%     百分号(%)
实例：

            $ awk '{ now=strftime( "%D", systime() ); print now }'
            $ awk '{ now=strftime("%m/%d/%y"); print now }'
14.8.3. 内建数学函数

Table 4.

函数名称     返回值
atan2(x,y)     y,x范围内的余切
cos(x)     余弦函数
exp(x)     求幂
int(x)     取整
log(x)     自然对数
rand()     随机数
sin(x)     正弦
sqrt(x)     平方根
srand(x)     x是rand()函数的种子
int(x)     取整，过程没有舍入
rand()     产生一个大于等于0而小于1的随机数
14.8.4. 自定义函数

在awk中还可自定义函数，格式如下：

        function name ( parameter, parameter, parameter, ... ) {
                        statements
                        return expression                  # the return statement and expression are optional
        }
15. How-to

如何把一行竖排的数据转换成横排？

awk '{printf("%s,",$1)}' filename



输出重定向

awk的输出重定向类似于shell的重定向。重定向的目标文件名必须用双引号引用起来。
$awk '$4 >=70 {print $1,$2 > "destfile" }' filename
$awk '$4 >=70 {print $1,$2 >> "destfile" }' filename
假如第一部分等于3那么打印整行
lxu@lxu-laptop:~$ cat abc
3 4 4
3 04 4
3 04 5
3 05 8
2 04 4
8 04 4

lxu@lxu-laptop:~$ awk '$1==3 {print$0}' abc
3 4 4
3 04 4
3 04 5
3 05 8
lxu@lxu-laptop:~$ awk '{if($1==3) {print$0}}' abc
3 4 4
3 04 4
3 04 5
3 05 8

问题：如题
以下是netstat -an的结果，只是部分。
tcp        0      0  10.134.91.63.9092      10.172.113.122.42324    ESTABLISHED
tcp        0      0  10.134.91.63.9092      10.172.113.122.36374    ESTABLISHED
tcp        0      0  10.134.91.63.9092      10.134.91.54.63975      ESTABLISHED
tcp        0      0  10.134.91.63.9092      10.134.91.54.52645      ESTABLISHED
tcp        0      0  10.134.91.63.9092      10.172.113.122.58975    ESTABLISHED
从netstat -an中统计出连接到本地9092端口最多的5个IP
awk '{if($4~/9092/)print $5}' URFIRL |cut -d. -f1-4 |uniq -c |sort -k1nr |head -5


sub()是替换第一个匹配
gsub()是替换所有匹配
gensub()是替换指定位置匹配


文件中有很多类似如下格式的行：
<ts name=" \abc\defghij\defdef"><summary name=" \xyz\abc\def">

用－替换掉ts name中的\但不替换summary name中的\.
lxu@lxu-laptop:~$ awk -F">" '{gsub(/\\/,"-",$1);print$1,$2}' test
<ts name=" -abc-defghij-defdef" <summary name=" \xyz\abc\def"



对awk稍微熟悉一点的朋友可能都知道， 在awk中使用system()函数可以调用系统命令， 比如:
echo "" | awk '{ system("touch hello.txt"); }'，  就可以在当前目录新建一个hello.txt文件。 但是实际用的时候， 可能情况没这么简单，  比如说一些变量是在当前shell环境指定的， 一些变量是在当前的awk中生成的， 这个时候如果把awk中的变量输出到shell环境， 可能会麻烦些， 该怎么办呢？

其实如果在c语言中有用过system()函数的话， 都知道其实可以把命令先存在一个字符串里， 然后在作为参数传递给system()， 在awk中的用法是：

cmd=sprintf(fmt, variable);
system(cmd);

比如我要生成几个文件， 文件名的格式是：基本前缀_起始日期_结束日期_文件记录数.txt， 其中起始日期和结束日期在shell环境中定义的， 文件记录数在awk中计算得到， 脚本大致是这个样子：


DATE_BEGIN=$1
DATE_END=$2

awk '
{
if($2=="abc"){ abc++; print $1 > "abc.txt" }
else{ xyz++; print $1 > "xyz.txt" }
}
END
{
cmd=sprintf("mv abc.txt abc_%s_%s_%d.txt", "'${DATE_BEGIN}'", "'${DATE_END}'", abc );
system(cmd);
cmd=sprintf("mv xyz.txt xyz_%s_%s_%d.txt", "'${DATE_BEGIN}'", "'${DATE_END}'", xyz );
system(cmd);
}' ur_file

举例：
[lxu@abintel lxu]$ uptime
 14:55:21 up 191 days, 10:21, 34 users,  load average: 1.05, 0.71, 1.10
[lxu@abintel lxu]$ uptime|awk '{if($NF>1) system("echo hello")}'
hello
可以判断apache僵尸进程来重启apache假设大于50
$ top -n 1|sed -n '2p'|awk '{if($(NF-1)==0)system("echo hello")}'
top -n 1|sed -n '2p'|awk '{if($(NF-1)==0)system("/sbin/ifconfig")}'
top -n 1|sed -n '2p'|awk '{if($(NF-1)>=0)system("sudo /usr/local/apache/bin/apachectl -k restart")}'

lxu@lxu-laptop:~$ cat test
7 176.90
lxu@lxu-laptop:~$ cat test|awk '{if($2>170) print$2 > "123"}'
lxu@lxu-laptop:~$ cat 123
176.90

$ awk '{("echo "$0"| md5sum ")|getline a; print a}'  md5


 /usr/bin/mysql --default-character-set=utf8 -h 60.28.211.168 -uabsms_control -pAibang_sms%115 -e 'use absms; select * from MSG_Inbox where Sender="10086" and MsgTitle like "%余额%" and MsgArrivedTime > date(now())'|awk '{print$11,$4}' |awk -F"，" '{print$1}'|sed 's/您的总账户余额为//g'|sed 's/元//g'|awk '{if($2<200) print$0 > "/home/lxu/sms/123"}'
[lxu@libai sms]$ /usr/bin/mysql --default-character-set=utf8 -h 60.28.211.168 -uabsms_control -pAibang_sms%115 -e 'use absms; select * from MSG_Inbox where Sender="10086" and MsgTitle like "%余额%" and MsgArrivedTime > date(now())'|awk '{print$11,$4}' |awk -F"，" '{print$1}'|sed 's/您的总账户余额为//g'|sed 's/元//g'|awk '{if($2<200) print$0 > "/home/lxu/sms/123.txt"}'|/usr/bin/perl /home/lxu/sendEmail.pl -t lxu@aibang.com -u "sms" -m "the state of sms" -f lxu@aibang.com -a /home/lxu/sms/123.txt
Mar 29 15:59:34 mail sendEmail.pl[1543]: Email was sent successfully!


求和：
lxu@lxu-laptop:~$ cat abc
abc 130
efg 160
efg 145
efg 145
ddd 148
ddd 144
ddd 143
ddd 143
abc 145
def 147
def 146
lxu@lxu-laptop:~$ awk '/abc/ {sum += $2};END{print sum}' abc
275
lxu@lxu-laptop:~$ awk '{S[$1]+=$2}END{for (a in S) print a,S[a]}' abc
def 293
abc 275
efg 450
ddd 578
lxu@lxu-laptop:~$ netstat -n|awk '/^tcp/'
tcp        0      0 192.168.1.94:42285      72.14.203.100:80        ESTABLISHED
lxu@lxu-laptop:~$ netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
CLOSE_WAIT 16
ESTABLISHED 6
FIN_WAIT1 1
SYN_SENT 7
TIME_WAIT


2) 自定义变量
1) 定义变量: varname=value (自定义变量不需先声明后使用，赋值语句同时完成变量定义和初始化)
2) 在表达式中出现不带双引号的字符串都被视为变量，如果之前未被赋值，默认值为0或空字符串。
3) 向命令行awk程序传递变量的值:
① Usage: awk 'awk_script' awkvar1=value1 awkvar2=value2 .... input_file
eg: awk '{if ($5 < ARG) print $0 }' ARG=100 input_file
② awkvar可以是awk内置变量或自定义变量。
③ awkvar的值将在awk开始对输入文件的第一条记录应用awk_script前传入。如果在awk_script中已经对某个变量赋值，那么在命令行上传人到该变量的值就会无效(实际上是awk_script中的赋值语句覆盖了从命令行上传入的值)。
④ 在awk脚本程序中不能直接使用shell的变量。通过使用下面的语法可达到这样的效果。
awk 'awk_script' awkvar1=shellvar1 awkvar2=shellvar2 .... input_file
eg: awk '{if (v1 == "root") {print "User name is root!"}}' v1=$USER input_file
⑤ 可以向awk脚本传递变量的值，与上面的类似。
awk_script_file awkvar1=value1 awkvar2=value2 ... input_file

lxu@lxu-laptop:~$ cat abc|awk '{if($2>145) print $0}'
efg 160
ddd 148
def 147
def 146
lxu@lxu-laptop:~$ cat abc|awk '{if($2>ARG) print $0}' ARG=145
efg 160
ddd 148
def 147
def 146

$ cat test1
2 3 4
3 4
4

统计单词重复出现的次数
grep -Po "\w+" abc
awk '{for(i=1;i<=NF;i++)print$i}' abc|sort|uniq -c|sort -rn
tr -s "\t| " "\n" < abc|sort|uniq -c
$ awk 'NF>1{for(i=1;i<=NF;i++)print $i;next}' test1
2
3
4
3
4
$ awk '{for(i=1;i<=NF;i++) print $i}' test1
$ awk 'NF>1{for(i=1;i<=NF;i++)print $i;next}1' test1
2
3
4
3
4
4

sed -i 's/[^a-Z]/ /g' filename
我想知道，next}后面那个1的作用是什么？MS少了它，源文件的最后一行不打印了。
tr -sc 'A-Za-z' '\n' < test
tr -sc 'A-Za-z' '\012' < test
tr -sc 'A-Za-z' '\012'用于分离文本test中的单词，然后每行显示一个单词。sort用于对文本中的句子按行排序。当每一行只有一个单词的时候，sort也就是对所有的单词排序。uniq -c 用于删除连续的相同的单词，并记录单词的连续次数。由于前面使用sort对所有单词排序了，所以uniq -c也就是统计每个单词的出现次数。

// shell 统计一篇文章中单词出现的频率
//
//-------------------------------
#! /bash/sh
# 功能：统计一篇文章中每个单词出现的频率，按顺序输出
# 使用：path-to-directory ［n］ < file
tr -cs a-zA-Z\' '\n' |
    tr A-Z a-z |
        sort |
            uniq -c |
                sort -k1,1nr -k2,2 |
                    awk ${1:-25}q
//-------------------------代码说明
1, tr 的 c 是取 set1 的补集(也就是不属于 set1)，将 set1 的补集替换为 set2
   s 是将 set1 中连续的要被替换的作为一个替换
   \' 是因为有些单词是缩写可能用到 '
2, 将大写字母转为小写
3, 排序
4, 统计每个单词重复出现的次数
5, 按单词出现的次数排序
   n 将代排序字段按整数排序
   r 反向排序(从大到小)
6, 输出


awk运算符
~ ~!     匹配正则表达式和不匹配正则表达式

6、awk '$1 ~ /101/ {print $1}' file 显示文件中第一个域匹配101的行（记录）
 用来在记录或者域内匹配正则表达式。
 如$ awk '$1 ~/^root/' test将显示test文件第一列中以root开头的行。。

lxu@lxu-laptop:~$ awk '$1~/abc/ {print$0}' abc 第一部分$1为abc
abc 130
abc 145
lxu@lxu-laptop:~$ awk '/abc/{print$0}' abc  #这个只是匹配这个的行
abc 130
abc 145
lxu@lxu-laptop:~$ awk '{if($1~/abc/) print$0}' abc
abc 130
abc 145



[root@]# cat a.txt
abc:123
bcd:123
def:123
abc:123
[root@]# awk 'BEGIN{FS=":"} {if ($1~/abc/) $2="444" ;print}' a.txt
abc 444
bcd:123
def:123
abc 444
[root@]# awk 'BEGIN{FS=":"} {if ($1~/abc/) $2="444" ;print}1' a.txt
abc 444
abc 444
bcd:123
bcd:123
def:123
def:123
abc 444
abc 444
[root@]#



awk的基本命令格式 awk 'pattern{action}'
    省略action时，默认action是{print}，如awk '1'就是awk '1{print}'
1就是1{print}或{print}的简写，能少敲几次键盘就少敲几次

awk的基本命令格式 awk 'pattern{action}'
    省略action时，默认action是{print}，如awk '1'就是awk '1{print}'
    省略pattern时，默认pattern就是真

awk 'BEGIN{FS=":"} {if ($1~/abc/) $2="444" ;{print}}'
就是awk 'BEGIN{FS=":"} 1{if ($1~/abc/) $2="444" ;{print}}'
至于action里面的格式，如{}里的if ($1~/abc/) $2="444" ;{print}

lxu@lxu-laptop:~$ echo 'a b c'|awk -v v="'" '{$2=v$2""v}1'
a 'b' c
lxu@lxu-laptop:/home/date$ echo a b c|awk -v v="'" '{$2=v$2v}{print}'
a 'b' c
lxu@lxu-laptop:/home/date$ echo a b c|awk -v v="'" '{$2=v$2v}1'
a 'b' c


还是用-v引入变量方便

man ascii

Oct   Dec   Hex   Char
047  39     27     '
awk 'BEGIN {print "a \x27""b""\047 c ?"}'


第五列百分比那个大于40%的就输出这一行
df -h | awk '$0 ~/dev\/sda[0-9]/{if($5~/[3-9][0-9].*/)print $0}'

每三行插入两行相同内容（比如要插入的两行为cc ,dd），请问怎么写脚本
awk '{print}NR%3==0{print "cc";print "bb"}'
awk '{print}NR%3==0' list
每一行后插入
$ awk '{print}{print "cc";print "bb"}' list

如何去除一个文件中，多行间第二列有重复的行
例如：
输入file.in：
1  aa  30
3  bb  31
4  aa  32
5  cc  33
6  cc  34
输出file.out:
3  bb  31

因为：第一行和第三行的第二列重复、第五行和第六行的第二列重复
awk 'NR==FNR{arr[$2]++}NR>FNR {if(arr[$2]==1) print $0}' abc abc

awk '{a[$2]=(!a[$2])?$0:1}END{for(i in a)if(a[i]!=1)print a[i]}' abc
比对下面这个
lxu@lxu-laptop:~$ netstat -n|awk '/^tcp/'
tcp        0      0 192.168.1.94:42285      72.14.203.100:80        ESTABLISHED
lxu@lxu-laptop:~$ netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
CLOSE_WAIT 16
ESTABLISHED 6
FIN_WAIT1 1
SYN_SENT 7
TIME_WAIT 4
a是最后一个字段s重复出现的次数

sort -k2 abc|awk '{print$2}'|uniq -c|awk '{if($1==1) print$2}'|while read line ;do grep "$line" abc ;done
3  bb  31

$ cat apache.conf
<VirtualHost *:80>
ServerAdmin [email]webmaster@test.com[/email]
DocumentRoot /home/vhost/test/public_html
ServerName test.com
ServerAlias [url]www.test.com[/url]
ErrorLog logs/test.com-error_log
TransferLog logs/test.com-access_log
</VirtualHost>

<VirtualHost *:80>
ServerAdmin [email]webmaster@abc.com[/email]
DocumentRoot /home/vhost/abc/public_html
ServerName abc.com
ServerAlias [url]www.abc.com[/url]
ErrorLog logs/abc.com-erro
</VirtualHost>
在虚拟主机中，找到 abc.com 的域名，把abc.com 整个虚拟主机输出。格式不变如下
$ awk 'BEGIN{RS="\n\n+"}/abc.com/' apache.conf
<VirtualHost *:80>
ServerAdmin [email]webmaster@abc.com[/email]
DocumentRoot /home/vhost/abc/public_html
ServerName abc.com
ServerAlias [url]www.abc.com[/url]
ErrorLog logs/abc.com-erro
</VirtualHost>
再假设每个</VirtualHost>后无空行的话可以如下
sed '/<\/VirtualHost>/G'

打印奇书和偶数行
对于这个hosts可以用另外一个办法egrep '[0-9]' hosts
lxu@lxu-laptop:/home/date$ cat hosts
192.168.2.100
sushi
192.168.2.101
liqingzhao
192.168.2.102
wanganshi
192.168.2.103
liyu
192.168.2.104
lijing
lxu@lxu-laptop:/home/date$ awk '{if(NR%2==1)print$0}' hosts

awk 'NR%2==1' file 也可以奇书

192.168.2.100
192.168.2.101
192.168.2.102
192.168.2.103
192.168.2.104

awk 'NR%2==0' file偶数
lxu@lxu-laptop:/home/date$ awk '{if(NR%2==0)print$0}' hosts
sushi
liqingzhao
wanganshi
liyu
lijing


22xinshuibaihe|||1441936988@qq.com|||10|||2f6c7bfa5600687235a8af6ce5d56311|||2010-04-04|||2|||
22xinshuibaihe|||1441936988@qq.com|||10|||2f6c7bfa5600687235a8af6ce5d56311|||2010-04-04|||2|||
22xinshuibaihe|||1441936988@qq.com|||10|||2f6c7bfa5600687235a8af6ce5d56311|||2010-04-04|||2|||
22xinshuibaihe|||1441936988@qq.com|||10|||2f6c7bfa5600687235a8af6ce5d56311|||2010-04-04|||2|||

awk -F'[|]+' '{print$2}'
[lxu@dufu tmp]$ awk -F'\\|\\|\\|' '{print$2}' test
1441936988@qq.com
1441936988@qq.com
1441936988@qq.com
1441936988@qq.com



对于awk '!a[$3]++'，需要了解3个知识点
1、awk数组知识，不说了
2、awk的基本命令格式 awk 'pattern{action}'
    省略action时，默认action是{print}，如awk '1'就是awk '1{print}'
3、var++的形式：先读取var变量值，再对var值+1

以数据
1 2 3
1 2 3
1 2 4
1 2 5
为例，对于awk '!a[$3]++'
awk处理第一行时： 先读取a[$3]值再自增，a[$3]即a[3]值为空(0)，即为awk '!0'，即为awk '1'，即为awk '1{print}'
awk处理第二行时： 先读取a[$3]值再自增，a[$3]即a[3]值为1，即为awk '!1'，即为awk '0'，即为awk '0{print}'
.............

最后实现的效果就是对于$3是第一次出现的行进行打印，也就是去除$3重复的行
[root@mail ~]# cat test
a ttpang  33
b jj  33
c dd  22
a aldfjlajd  22
d asdf  11
c aa  tt
[root@mail ~]# awk '!($1 in a) {a[$1];print}' test
[root@mail ~]# awk '!a[$1]++' test
a ttpang  33
b jj  33
c dd  22
d asdf  11
[root@mail ~]# awk 'a[$1]++' test
a aldfjlajd  22
c aa  tt

现有文本文件日志：
游戏id   在线时常time   QQ号码
6534    456           37354893
6500    056           564572105
6534    4156         37354893
6500    2456         564572100
要求，写shell脚本对改文件按照第二列在线时常排序，然后，统计每个QQ号总共时长和。

[lxu@abintel ~]$ sort -k2n test.txt|awk 'NR>=1{a[$3]+=$2}END{for (i in a) print i,a[i]}'
[lxu@abintel ~]$ sort -k2n test.txt|awk '{S[$NF]+=$2}END{for(i in S)print i,S[i]}'
[lxu@abintel ~]$ sort -k2n test.txt|awk '{a[$3]+=$2}END{for (i in a) print i,a[i]}'
564572100 2456
564572105 56
37354893 4612


本帖最后由 ybbdnvjfd 于 2010-07-12 16:00 编辑


cat file1

ice
cat
rrr

cat file2

1    ybb
2     ice
3    box
4    cat
5    qqq
6    www
7     rrr
我用什么方法把file1里的文件字符和file2里的文件字符相匹配并打印出匹配字符的第二列。
awk 'NR==FNR{a[$1];next}($1 in a)' file1 file2
awk 'NR==FNR{a[$1];next}{if($2 in a)print $1}' file1 file2




读10行并写入另入一个文件，直至被读完
awk 'NR%10==1{i++}{print > "file"i}' urfile
顺便复习下$ awk '{print NR,$0}' test将输出test文件中所有记录，并在记录前显示记录号


|||分隔符号
echo "宁波市格力空调专卖店|||cgenping@126.cnm|||10|||7e73d9bd17bdde25af5b0d62b61d2b112010-05-04|||2|||"|awk -F"[|][|][|]" '{print$2}'
cgenping@126.com

awk -F"[|][|][|]" '{print$2}'
awk -F"[|]+" '{print$2}'

例子如下：第二列是时间按照秒来计算，当小于60秒的时候按照1分钟计算，当大于60秒的时候，可以除以60计算分钟。如150秒应该是150/60=2分钟多，其实就是3分钟了
$ cat 123
a 1
b 3
c 8
d 5
e 5
c 4
e 2
c 3
a 3
d 30
c 49
d 150
f 120
d 130
d 180
c 150
如下办法：
awk '{if($2<60)print 1;else print int(($2-1)/60+1)}'|awk '{sum += $1}END{print sum}'
参考：如何做到不能整除就进位
http://bbs.chinaunix.net/viewthread.php?tid=1597049&extra=&page=1
分子先-1，除完再+1
echo "scale=0;(10-1)/9+1" | bc
就是数学啊。:)

我观察了下面的结果
echo "scale=0;9/9" | bc
echo "scale=0;10/9" | bc
……
echo "scale=0;18/9" | bc
echo "scale=0;19/9" | bc

就推导出了上面的公式。公示也可以理解成：(分子+分母-1)/分母 或 分子/分母+(分母-1)/分母
就是数学啊。:)

我观察了下面的结果
echo "scale=0;9/9" | bc
echo "scale=0;10/9" | bc
……
echo "scale=0;18/9" | bc
echo "scale=0;19/9" | bc

就推导出了上面的公式。公示也可以理解成：(分子+分母-1)/分母 或 分子/分母+(分母-1)/分母











输入：a.txt

a    1
a    3
a    6
b    2
b    4
b    7
c    5
c    8
d    9

输出：b.txt
a    0
a    2
a    3
b    0
b    2
b    3
c    0
c    3
d    0
======
解释：输出文件b.txt的第一列仍然为a.txt的第一列（a.txt的第一列已经排序）
第二列的值与第一列有如下关系：
（1）如果对应的第一列值首次出现，则b.txt第二列输出为0。譬如，b.txt的第一行输出为“a  0”即因为此行的a首次出现；
（2）如果对应的第二列值出现过，则b.txt第二列为当前行的值减去上一行的值。譬如，b.txt的第二行输出“a    2”即a.txt第一行的3减去第二行的1
$ awk '{if(!a[$1]++){print $1,0}else{print $1,$2-tmp};tmp=$2}' a.txt
第一列已经排序，没必要用数组了。
awk '{if($1!=s)print $1,0;else print $1,$2-t;s=$1;t=$2}' a.txt > b.txt
awk '{if(!a[$1]++) print $1,0 ; else print $1,$2-t; t=$2}'

变换456的文本格式
lxu@lxu-laptop:/home/date/shell$ cat 456
host01[192.168.2.100]
httpd            ok
tomcat               ok
sendmail               ok
host02[192.168.2.101]
httpd            ok
postfix               ok
host03[192.168.2.102]
mysqld            ok
httpd               ok
$ awk '{if($0 ~ /host/) a=$0;else print a$0}'
$ awk '/host/{s=$0;next}{print s,$0}' 456
host01[192.168.2.100] httpd            ok
host01[192.168.2.100] tomcat               ok
host01[192.168.2.100] sendmail               ok
host02[192.168.2.101] httpd            ok
host02[192.168.2.101] postfix               ok
host03[192.168.2.102] mysqld            ok
host03[192.168.2.102] httpd               ok
lxu@lxu-laptop:/home/date/shell$ awk '/host/{s=$0}{print s}' 456
host01[192.168.2.100]
host01[192.168.2.100]
host01[192.168.2.100]
host01[192.168.2.100]
host02[192.168.2.101]
host02[192.168.2.101]
host02[192.168.2.101]
host03[192.168.2.102]
host03[192.168.2.102]
host03[192.168.2.102]
lxu@lxu-laptop:/home/date/shell$ awk '/host/{next}{print$0}' 456
httpd            ok
tomcat               ok
sendmail               ok
httpd            ok
postfix               ok
mysqld            ok
httpd               ok
通过next在某条件时跳过该行，对下一行执行操作
跳过s=$0,对下行操作
lxu@lxu-laptop:/home/date/shell$ awk '/host/{s=$0;next}{print s,$0}' 456
host01[192.168.2.100] httpd            ok
host01[192.168.2.100] tomcat               ok
host01[192.168.2.100] sendmail               ok
host02[192.168.2.101] httpd            ok
host02[192.168.2.101] postfix               ok
host03[192.168.2.102] mysqld            ok
host03[192.168.2.102] httpd               ok

看这个ip和掩码的变化
$ awk '{print$0}' ip
162.105/16
166.111/16
202.4.128/19
202.112.64/18
202.112.128/17
202.113/16

$ awk -F '[/,]' '{n=split($1,b,".");if(n==2)print $1".0.0/"$2;else if(n==3)print $1".0/"$2}' ip
162.105.0.0/16
166.111.0.0/16
202.4.128.0/19
202.112.64.0/18
202.112.128.0/17
202.113.0.0/16
lxu@lxu-laptop:~/aibang/awk$ echo 'scale=4;4*5.208'|bc
20.832
lxu@lxu-laptop:~/aibang/awk$ awk 'BEGIN{a=4;b=5.208;print a*b}'
20.832


对IP求和

awk '{S[$2]+=$1}END{for (a in S) print S[a],a}' a.sh

 105238 101.12.109.162
   3831 106.85.137.147
  33203 110.250.152.76
   3416 111.12.100.120
   5756 111.12.100.237
  15576 111.27.248.96
   5024 111.59.180.174
 124438 112.123.77.36
     32 106.85.137.147
netstat -n|awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

cat test.haha  | sort -n | awk -F: '{S[$1]=$1;N[$1]=$2+N[$1]}END{for(i in S) print S[i],N[i]}' | sort -n -k 2 -r | head
Henan 42585
陕西省西安市 21245
安徽省合肥市 17214
Hebei 15936
Beijing 15028
Jiangxi 14600
Shanxi 13170
Anhui 12839
Heilongjiang 10340
Hunan 10303


取POST或者GET这个 并且是200状态的
awk '$6 ~ /POST/ && $9 ~ /200/' /usr/local/nginx/logs/login_intra_access.log
取POST或者GET这个 并且不是200状态的
awk '$6 ~ /POST/ && $9 !~ /200/' /usr/local/nginx/logs/login_intra_access.log
再取某天
awk '$6 ~ /POST/ && $9 !~ /200/' /usr/local/nginx/logs/login_intra_access.log|fgrep "21/Mar/2018"

netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

ss -ant | awk 'NR>1 {++s[$1]} END {for(k in s) print k,s[k]}'


$ cat /tmp/domain_ip/nnf_ip.txt
app-dynamics-proxy. 10.235.20.3
ccc-ppt-pgb. 10.98.14.88
www.baidu.com. 100.100.102.42
www.baidu.com. 100.100.102.43
www.baidu.com. 100.100.102.44
ipc-dev-pgb. 10.98.33.154

这个样子的，想要第一列相当的情况下 转化为
app-dynamics-proxy. 10.235.20.3
ccc-ppt-pgb. 10.98.14.88
www.baidu.com. 100.100.102.42 100.100.102.43 100.100.102.44
ipc-dev-pgb. 10.98.33.154

cat /tmp/domain_ip/nnf_ip.txt  | awk '{S[$1]=$2","S[$1]} END {for(i in S) print i,S[i]}' | sed 's/,$//g'



01
02;
03
04
05;
06
07;
弄成
01 02；
03 04 05；
06 07；

awk '{if ($0~/;$/) printf("%s\n", $0);else printf("%s ",$0)}'


将如下文本按第一列为主key，将相同的第五列值追加到同一行
awk '{a[$1]=a[$1]"|"$5}END{for (i in a) {print i,a[i]"|"}}' /tmp/test-zone-test-private-access-hardcode.txt /tmp/test-zone-domain-file.txt
awk '{S[$1]=$5","S[$1]}END{for (a in S) print a, S[a]}' /tmp/test-zone-test-private-access-hardcode.txt /tmp/test-zone-domain-file.txt
awk '{S[$1]=$5","S[$1]}END{for (a in S) print a, S[a]}' /tmp/test-zone-test-private-access-hardcode.txt /tmp/test-zone-domain-file.txt|sed 's/,$//g'
awk '{S[$1]=$5","S[$1]} END {for(a in S) print a, S[a]}'  /tmp/test-zone-test-private-access-hardcode.txt /tmp/test-zone-domain-file.txt|sed 's/,$//g'

[d5145841@hkl20111021 ~]$ cat /tmp/test-zone-test-private-access-hardcode.txt
wgdc-drn-03.cloud.zone.domain. 300 IN A 192.168.192.13
apps.cf.wgdc-drn-03.cloud.zone.domain. 300 IN A 192.168.192.197
04.cloud.zone.domain. 300 IN A 192.168.192.222


$ cat /tmp/test-zone-domain-file.txt
wgdc-drn-03.cloud.zone.domain. 300 IN A 10.171.192.156
apps.cf.wgdc-drn-03.cloud.zone.domain. 300 IN A 10.171.192.156
04.cloud.zone.domain. 300 IN A 11.192.159.23
